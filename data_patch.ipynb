{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7a41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01960b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1128_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05c0a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已處理 5966 筆資料的發布日期\n"
     ]
    }
   ],
   "source": [
    "# 找出TAICCA_ID中沒有「/」且min_publish_date為空的資料\n",
    "mask = (~df['TAICCA_ID'].str.contains('/', na=False)) & (df['min_publish_date'].isna())\n",
    "\n",
    "# 對這些資料，從各平台的發布日期中找出有值的日期來填補\n",
    "for idx in df[mask].index:\n",
    "    # 收集各平台的發布日期\n",
    "    dates = []\n",
    "    for col in ['bookscom_publish_date', 'eslite_publish_date', 'kingstone_publish_date', 'sanmin_publish_date']:\n",
    "        if pd.notna(df.loc[idx, col]) and str(df.loc[idx, col]).strip():\n",
    "            dates.append(df.loc[idx, col])\n",
    "    \n",
    "    # 如果有找到日期，就填入min_publish_date和max_publish_date\n",
    "    if dates:\n",
    "        # 直接使用第一個找到的日期，不進行比較\n",
    "        df.loc[idx, 'min_publish_date'] = dates[0]\n",
    "        df.loc[idx, 'max_publish_date'] = dates[0]\n",
    "\n",
    "print(f\"已處理 {mask.sum()} 筆資料的發布日期\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ad3e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已統一日期格式為YYYY-MM-DD\n"
     ]
    }
   ],
   "source": [
    "# 統一min_publish_date和max_publish_date的格式為YYYY-MM-DD\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def standardize_date_format(date_str):\n",
    "    \"\"\"將各種日期格式統一為YYYY-MM-DD格式\"\"\"\n",
    "    if pd.isna(date_str) or not str(date_str).strip():\n",
    "        return date_str\n",
    "    \n",
    "    date_str = str(date_str).strip()\n",
    "    \n",
    "    # 如果已經是YYYY-MM-DD格式，直接返回\n",
    "    if re.match(r'^\\d{4}-\\d{2}-\\d{2}$', date_str):\n",
    "        return date_str\n",
    "    \n",
    "    # 處理各種可能的日期格式\n",
    "    try:\n",
    "        # 嘗試解析M/D/YY格式 (如 7/8/25)\n",
    "        if re.match(r'^\\d{1,2}/\\d{1,2}/\\d{2}$', date_str):\n",
    "            month, day, year = date_str.split('/')\n",
    "            # 假設YY格式的年份都是20XX年\n",
    "            year = f\"20{year}\"\n",
    "            return f\"{year}-{month.zfill(2)}-{day.zfill(2)}\"\n",
    "        \n",
    "        # 嘗試解析YYYY-M-D格式\n",
    "        if re.match(r'^\\d{4}-\\d{1,2}-\\d{1,2}$', date_str):\n",
    "            parts = date_str.split('-')\n",
    "            return f\"{parts[0]}-{parts[1].zfill(2)}-{parts[2].zfill(2)}\"\n",
    "        \n",
    "        # 嘗試其他常見格式\n",
    "        for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%m/%d/%Y', '%d/%m/%Y']:\n",
    "            try:\n",
    "                parsed_date = datetime.strptime(date_str, fmt)\n",
    "                return parsed_date.strftime('%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"無法解析日期格式: {date_str}\")\n",
    "        return date_str\n",
    "    \n",
    "    return date_str\n",
    "\n",
    "# 處理min_publish_date和max_publish_date欄位\n",
    "for col in ['min_publish_date', 'max_publish_date', 'bookscom_publish_date', 'eslite_publish_date', 'kingstone_publish_date', 'sanmin_publish_date']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(standardize_date_format)\n",
    "\n",
    "print(\"已統一日期格式為YYYY-MM-DD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d80c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到的title相關欄位: ['title', 'bookscom_title', 'eslite_title', 'kingstone_title', 'sanmin_title', 'processed_title', 'bookscom_processed_title', 'eslite_processed_title', 'kingstone_processed_title', 'sanmin_processed_title', 'original_title', 'bookscom_original_title', 'eslite_original_title', 'kingstone_original_title', 'sanmin_original_title']\n",
      "使用 'title' 欄位進行A-Z排序\n",
      "排序完成，共 10260 筆資料\n"
     ]
    }
   ],
   "source": [
    "# 以title進行A-Z排序\n",
    "# 首先檢查是否有title相關的欄位\n",
    "title_columns = [col for col in df.columns if 'title' in col.lower()]\n",
    "print(f\"找到的title相關欄位: {title_columns}\")\n",
    "\n",
    "# 使用主要的title欄位進行排序，如果沒有則使用第一個找到的title欄位\n",
    "if 'title' in df.columns:\n",
    "    sort_column = 'title'\n",
    "elif 'bookscom_title' in df.columns:\n",
    "    sort_column = 'bookscom_title'\n",
    "elif title_columns:\n",
    "    sort_column = title_columns[0]\n",
    "else:\n",
    "    print(\"警告: 找不到title欄位，將使用第一個欄位進行排序\")\n",
    "    sort_column = df.columns[0]\n",
    "\n",
    "print(f\"使用 '{sort_column}' 欄位進行A-Z排序\")\n",
    "\n",
    "# 進行排序，將空值放在最後\n",
    "df = df.sort_values(by=sort_column, ascending=True, na_position='last')\n",
    "\n",
    "# 重置索引\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"排序完成，共 {len(df)} 筆資料\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d043171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1201_output.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d461cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_2/w3bch_7n5c9_zvnqztg1b6tc0000gn/T/ipykernel_33830/1774769435.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,15,16,17,19,20,21,22,24,25,26,27,29,30,31,32,34,35,36,37,39,40,41,42,43,45,46,47,48,49,50,51,52,54,55,56,57,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_source = pd.read_csv('input_data/paper_source_1124.csv')\n"
     ]
    }
   ],
   "source": [
    "df_source = pd.read_csv('input_data/paper_source_1124.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e62338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已填補 17216 筆未合併資料的基本欄位（title, isbn, processed_title, original_title, author, translator, publisher）\n"
     ]
    }
   ],
   "source": [
    "# 找出未合併資料（TAICCA_ID 中沒有「/」）\n",
    "unmerged_mask = ~df_source['TAICCA_ID'].str.contains('/', na=False)\n",
    "\n",
    "# 定義需要填補的欄位及其對應的各平台欄位\n",
    "fill_mapping = {\n",
    "    'title': ['bookscom_title', 'eslite_title', 'kingstone_title', 'sanmin_title'],\n",
    "    'isbn': ['bookscom_isbn', 'eslite_isbn', 'kingstone_isbn', 'sanmin_isbn'],\n",
    "    'processed_title': ['bookscom_processed_title', 'eslite_processed_title', 'kingstone_processed_title', 'sanmin_processed_title'],\n",
    "    'original_title': ['bookscom_original_title', 'eslite_original_title', 'kingstone_original_title', 'sanmin_original_title'],\n",
    "    'author': ['bookscom_author', 'eslite_author', 'kingstone_author', 'sanmin_author'],\n",
    "    'translator': ['bookscom_translator', 'eslite_translator', 'kingstone_translator', 'sanmin_translator'],\n",
    "    'publisher': ['bookscom_publisher', 'eslite_publisher', 'kingstone_publisher', 'sanmin_publisher']\n",
    "}\n",
    "\n",
    "# 對每個未合併的資料進行填補\n",
    "fill_count = 0\n",
    "for idx in df_source[unmerged_mask].index:\n",
    "    has_filled = False\n",
    "    \n",
    "    # 處理一般欄位\n",
    "    for target_col, source_cols in fill_mapping.items():\n",
    "        # 如果目標欄位是空的\n",
    "        if pd.isna(df_source.loc[idx, target_col]) or not str(df_source.loc[idx, target_col]).strip():\n",
    "            # 從各平台欄位中找第一個有值的\n",
    "            for source_col in source_cols:\n",
    "                if pd.notna(df_source.loc[idx, source_col]) and str(df_source.loc[idx, source_col]).strip():\n",
    "                    df_source.loc[idx, target_col] = df_source.loc[idx, source_col]\n",
    "                    has_filled = True\n",
    "                    break\n",
    "    \n",
    "    if has_filled:\n",
    "        fill_count += 1\n",
    "\n",
    "print(f\"已填補 {fill_count} 筆未合併資料的基本欄位（title, isbn, processed_title, original_title, author, translator, publisher）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c200a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已填補 17211 筆未合併資料的發布日期（min_publish_date, max_publish_date）\n"
     ]
    }
   ],
   "source": [
    "# 處理 min_publish_date 和 max_publish_date\n",
    "date_fill_count = 0\n",
    "for idx in df_source[unmerged_mask].index:\n",
    "    # 如果 min_publish_date 或 max_publish_date 是空的\n",
    "    if pd.isna(df_source.loc[idx, 'min_publish_date']) or pd.isna(df_source.loc[idx, 'max_publish_date']):\n",
    "        # 收集各平台的發布日期\n",
    "        dates = []\n",
    "        for col in ['bookscom_publish_date', 'eslite_publish_date', 'kingstone_publish_date', 'sanmin_publish_date']:\n",
    "            if pd.notna(df_source.loc[idx, col]) and str(df_source.loc[idx, col]).strip():\n",
    "                dates.append(df_source.loc[idx, col])\n",
    "        \n",
    "        # 如果有找到日期，就填入（使用第一個找到的日期）\n",
    "        if dates:\n",
    "            if pd.isna(df_source.loc[idx, 'min_publish_date']) or not str(df_source.loc[idx, 'min_publish_date']).strip():\n",
    "                df_source.loc[idx, 'min_publish_date'] = dates[0]\n",
    "            if pd.isna(df_source.loc[idx, 'max_publish_date']) or not str(df_source.loc[idx, 'max_publish_date']).strip():\n",
    "                df_source.loc[idx, 'max_publish_date'] = dates[0]\n",
    "            date_fill_count += 1\n",
    "\n",
    "print(f\"已填補 {date_fill_count} 筆未合併資料的發布日期（min_publish_date, max_publish_date）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4e5b93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已填補 17216 筆未合併資料的價格（price，取最大值）\n"
     ]
    }
   ],
   "source": [
    "# 處理 price（取各平台價格的最大值）\n",
    "price_fill_count = 0\n",
    "for idx in df_source[unmerged_mask].index:\n",
    "    # 如果 price 是空的\n",
    "    if pd.isna(df_source.loc[idx, 'price']) or str(df_source.loc[idx, 'price']).strip() == '':\n",
    "        # 收集各平台的價格\n",
    "        prices = []\n",
    "        for col in ['bookscom_original_price', 'eslite_original_price', 'kingstone_original_price', 'sanmin_original_price']:\n",
    "            if pd.notna(df_source.loc[idx, col]):\n",
    "                try:\n",
    "                    price = float(df_source.loc[idx, col])\n",
    "                    if price > 0:  # 只考慮大於 0 的價格\n",
    "                        prices.append(price)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # 如果有找到價格，取最大值填入\n",
    "        if prices:\n",
    "            df_source.loc[idx, 'price'] = max(prices)\n",
    "            price_fill_count += 1\n",
    "\n",
    "print(f\"已填補 {price_fill_count} 筆未合併資料的價格（price，取最大值）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665046d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已儲存至 input_data/paper_source_1201.csv\n"
     ]
    }
   ],
   "source": [
    "# 儲存處理後的檔案\n",
    "df_source.to_csv('input_data/paper_source_1201.csv', index=False, encoding='utf-8')\n",
    "print(\"已儲存至 input_data/paper_source_1201.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5215913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
